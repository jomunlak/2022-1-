
신기한 커널 기법
 
수학적 머신러닝의 왕자 SVM (Support Vector Machine)
 커널 기법의 확장형
 두 클래스 사이를 매끄러운 곡선으로 나누어준다.

속성을 추가해서 곡선을 만든다??


import numpy as np
import pandas as pd
import mglearn
import matplotlib.pyplot as plt 
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_breast_cancer
from sklearn.svm import SVC
cancer = load_breast_cancer()

X = cancer.data[:,:2]
y = cancer.target
plt.scatter(X[:,0], X[:,1], c = y, alpha = 0.2)


# 곡선으로 확률 분포를 그리는 코드
xmax = X[:,0].max()+1
xmin = X[:,0].min()-1
ymax = X[:,1].max()+1
ymin = X[:,1].min()-1

xx=np.linspace(xmin,xmax,200)
yy=np.linspace(ymin,ymax,200)
data1, data2 = np.meshgrid(xx,yy)
X_grid = np.c_[data1.ravel(), data2.ravel()]
decision_values = model.predict_proba(X_grid)[:,0] # 등고선을 위해 확률점수를 구함

sv=model.support_vectors_

fig=plt.figure(figsize=[14,12])

# show probability countour
CS=plt.contour(data1,data2,decision_values.reshape(data1.shape),levels=[0.01, 0.1, 0.2, 0.5, 0.8, 0.9, 0.99])
plt.clabel(CS, inline=2, fontsize=10)

# show support vectors
plt.scatter(sv[:,0], sv[:,1], marker='s', c= 'k', s=100)

# show train samples
plt.scatter(X[:,0][y==0],X[:,1][y==0],marker='o',c='r',label='malignant')
plt.scatter(X[:,0][y==1],X[:,1][y==1],marker='^',c='y',label='benign')

plt.legend()
plt.colorbar(CS,shrink=0.5)
plt.xlabel(cancer.feature_names[0])
plt.ylabel(cancer.feature_names[1])
plt.title('SVM - decision bounds',fontsize=20)


 SCM 에서 중요한 옵션 두 가지, C옵션과  gamma 옵션 
 이 두 가지 옵션을 조정함에따라 결과가 크게 바뀐다.

과적합 이슈

지나치게 과거 데이터에 꼭 맞게 만들어진 모델을 과대적합 되었다고한다
반대로 너무 대강 만들어진 모델은 과소적합 되었다고 한다.

정규화 : 속성들의 크기를 맞춘 박스플롯으로 표시한다.






